{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337acb8-f003-4ada-af09-cbe4db26eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eee082-4ac6-40c8-b96b-a217f4f1992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rents data\n",
    "Rents = pd.read_csv('Rents & Transactions/rents.csv', delimiter=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc3ad6-8c2a-4b43-80e2-b752f8596e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transactions Data\n",
    "Transactions = pd.read_csv('Rents & Transactions/transactions.csv', delimiter=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49fd86-169f-47aa-a8db-54af39acf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rents.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f758b-4d9e-4dd8-b7cd-fe91dd2ab2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601782d-b93d-41a3-acb2-5200dce23a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Property Size (sq.m)' and 'Annual Amount' to numeric\n",
    "Rents['Property Size (sq.m)'] = pd.to_numeric(Rents['Property Size (sq.m)'], errors='coerce')\n",
    "Rents['Annual Amount'] = pd.to_numeric(Rents['Annual Amount'], errors='coerce')\n",
    "Rents['Contract Amount'] = pd.to_numeric(Rents['Contract Amount'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e02f9c-67a3-4562-bb7d-64b1cf4fc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime\n",
    "Rents['Registration Date'] = pd.to_datetime(Rents['Registration Date'], errors='coerce')\n",
    "Rents['Start Date'] = pd.to_datetime(Rents['Start Date'], errors='coerce')\n",
    "Rents['End Date'] = pd.to_datetime(Rents['End Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111360a-3bc0-40d8-a252-de0d7beea619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "Rents['Contract Duration (days)'] = (Rents['End Date'] - Rents['Start Date']).dt.days\n",
    "# Rents['Price per sq.m'] = Rents['Annual Amount'] / Rents['Property Size (sq.m)']\n",
    "\n",
    "# Rents['Price per sq.m'] = pd.to_numeric(Rents['Price per sq.m'], errors='coerce')\n",
    "\n",
    "# Check results\n",
    "print(Rents.info())\n",
    "print(Rents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6a0bc-b0a0-46b8-a64b-47f00cabcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers using IQR method\n",
    "Q1 = Rents['Annual Amount'].quantile(0.25)\n",
    "Q3 = Rents['Annual Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "Rents['Annual Amount'] = Rents['Annual Amount'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Plot after outlier handling\n",
    "sns.boxplot(x=Rents['Annual Amount'])\n",
    "plt.title(\"Boxplot of Annual Amount After Outlier Handling\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3bf05e-6f3f-4205-a8cd-6c81b9e49ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 'End Date' based on average duration\n",
    "avg_duration = Rents['Contract Duration (days)'].mean()\n",
    "Rents['End Date'] = Rents['End Date'].fillna(\n",
    "    Rents['Start Date'] + pd.to_timedelta(avg_duration, unit='d')\n",
    ")\n",
    "\n",
    "# Recalculate 'Contract Duration (days)'\n",
    "Rents['Contract Duration (days)'] = (Rents['End Date'] - Rents['Start Date']).dt.days\n",
    "\n",
    "# Check updated missing values\n",
    "print(Rents[['End Date', 'Contract Duration (days)']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ccb9c-e3af-4b99-be4b-89e8778a7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target variable analysis\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(Rents['Annual Amount'], kde=True, bins=50)\n",
    "plt.title(\"Distribution of Annual Amount\")\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=Rents['Annual Amount'])\n",
    "plt.title(\"Boxplot of Annual Amount\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numerical features\n",
    "numerical_cols = ['Annual Amount', 'Contract Amount', 'Property Size (sq.m)']\n",
    "correlation = Rents[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Categorical features vs Annual Amount\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(x='Property Type', y='Annual Amount', data=Rents)\n",
    "plt.title(\"Property Type vs Annual Amount\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Missing data visualization\n",
    "missing_data = Rents.isnull().mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "missing_data[missing_data > 0].plot(kind='bar')\n",
    "plt.title(\"Missing Data Percentage\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113254f-135b-4a0d-8978-5fcf0b7b1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for 'Building' in Property Type\n",
    "unit_data = Rents[Rents['Property Type'] == 'Building']\n",
    "\n",
    "# Summary statistics for 'Unit'\n",
    "print(unit_data['Annual Amount'].describe())\n",
    "\n",
    "# Plot distribution of 'Annual Amount' for 'Unit'\n",
    "sns.histplot(unit_data['Annual Amount'], kde=True, bins=50)\n",
    "plt.title(\"Distribution of Annual Amount for 'Unit'\")\n",
    "plt.show()\n",
    "\n",
    "# Compare with other property types\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(x='Property Type', y='Annual Amount', data=Rents)\n",
    "plt.title(\"Annual Amount by Property Type\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c6929-5f72-4633-8606-cb5962c75c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Convert columns to numeric (this will coerce invalid parsing to NaN)\n",
    "Rents = Rents.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# After conversion, check for infinity and large values again\n",
    "print(\"Check for infinity values:\")\n",
    "print((Rents == float('inf')).sum())\n",
    "print((Rents == float('-inf')).sum())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc4520-2b93-4334-9bfb-71c818e1bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average prices the previous month/week (for the same kind of property)\n",
    "\n",
    "# Step 1: Convert dates to datetime format\n",
    "Rents['Registration Date'] = pd.to_datetime(Rents['Registration Date'], errors='coerce')\n",
    "\n",
    "# Step 2: Extract year, month, and week from Transaction Date\n",
    "Rents['Year'] = Rents['Registration Date'].dt.year\n",
    "Rents['Month'] = Rents['Registration Date'].dt.month\n",
    "Rents['Week'] = Rents['Registration Date'].dt.isocalendar().week\n",
    "\n",
    "# Step 3: Define property characteristics for grouping\n",
    "property_characteristics = ['Area', 'Property Type', 'Property Sub Type', 'Usage', 'Is Free Hold?']\n",
    "\n",
    "# Step 4: Calculate average prices for the previous month\n",
    "Rents['Prev_Month_Avg_Price'] = (\n",
    "    Rents.groupby(property_characteristics + ['Year', 'Month'])['Annual Amount']\n",
    "    .transform(lambda x: x.shift().mean())\n",
    ")\n",
    "\n",
    "# Step 5: Calculate average prices for the previous week\n",
    "Rents['Prev_Week_Avg_Price'] = (\n",
    "    Rents.groupby(property_characteristics + ['Year', 'Week'])['Annual Amount']\n",
    "    .transform(lambda x: x.shift().mean())\n",
    ")\n",
    "\n",
    "# Verify the new columns\n",
    "print(Rents[['Prev_Month_Avg_Price', 'Prev_Week_Avg_Price']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0df55-2aa7-4de3-9c6c-433dd797dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Handle missing values\n",
    "Rents['Property Sub Type'].fillna('Unknown', inplace=True)\n",
    "Rents['Room(s)'].fillna('Unknown', inplace=True)\n",
    "Rents['Parking'].fillna('Unknown', inplace=True)\n",
    "Rents['Nearest Metro'].fillna('Unknown', inplace=True)\n",
    "Rents['Nearest Mall'].fillna('Unknown', inplace=True)\n",
    "Rents['Nearest Landmark'].fillna('Unknown', inplace=True)\n",
    "Rents['Project'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop rows where the target variable 'Amount' is missing (if any)\n",
    "Rents.dropna(subset=['Annual Amount'], inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af40035-9386-4236-9762-23c5783639cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db78fc-b5f6-412f-aaa6-654bafe6c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Prepare the data\n",
    "# Drop rows where 'Annual Amount' is missing\n",
    "Rents = Rents.dropna(subset=['Annual Amount'])\n",
    "\n",
    "# Define features and target\n",
    "X = Rents.drop(columns=['Annual Amount', 'Ejari Contract Number', 'Registration Date', 'Start Date', 'End Date'])\n",
    "y = Rents['Annual Amount']\n",
    "\n",
    "# 2. Train-Test Split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a802010-027f-40ac-9c4d-ee7c0fd33a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost Model\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Handle NaN in categorical features\n",
    "cat_columns = X_train.select_dtypes(include=['object']).columns\n",
    "for col in cat_columns:\n",
    "    X_train[col] = X_train[col].fillna('Unknown')\n",
    "    X_test[col] = X_test[col].fillna('Unknown')\n",
    "\n",
    "# Categorical features: Get the indices of the categorical columns in X_train\n",
    "cat_features = [i for i, col in enumerate(X_train.columns) if X_train[col].dtype == 'object']\n",
    "\n",
    "# Step 1: Define the CatBoost model\n",
    "model = CatBoostRegressor(iterations=1000,  # Number of boosting iterations\n",
    "                          learning_rate=0.1,  # Learning rate\n",
    "                          depth=6,  # Tree depth\n",
    "                          cat_features=cat_features,  # List of categorical feature indices\n",
    "                          random_seed=42,  # Random seed for reproducibility\n",
    "                          verbose=200)  # Print progress every 200 iterations\n",
    "\n",
    "# Step 2: Train the model\n",
    "model.fit(X_train, y_train, cat_features=cat_features)\n",
    "\n",
    "# Step 3: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)  # Calculate R² Score\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"MSE: {mse:.4f}\")   # Mean Squared Error\n",
    "print(f\"RMSE: {rmse:.4f}\")  # Root Mean Squared Error\n",
    "print(f\"R² Score: {r2:.4f}\")  # R-squared score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1e067-31a1-450c-8e32-4ba50e6d9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance from the trained model\n",
    "feature_importance = model.get_feature_importance()\n",
    "\n",
    "# Create a DataFrame to map feature names with importance scores\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort the importance values in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for CatBoost')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important features on top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cef29-d08f-45ec-ae2d-93c2fec50918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Model\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Convert categorical columns to category dtype\n",
    "categorical_columns = ['Version', 'Area', 'Is Free Hold?', 'Property Type', \n",
    "                       'Property Sub Type', 'Usage', 'Nearest Metro', \n",
    "                       'Nearest Mall', 'Nearest Landmark', 'Master Project', 'Project']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "# Step 2: Define the LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', \n",
    "                              num_iterations=1000,  # Number of boosting iterations\n",
    "                              learning_rate=0.1,  # Learning rate\n",
    "                              max_depth=6,  # Tree depth\n",
    "                              random_state=42)  # Random seed for reproducibility\n",
    "\n",
    "# Step 3: Train the model with categorical features\n",
    "lgb_model.fit(X_train, y_train, categorical_feature=categorical_columns)\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "rmse_lgb = mse_lgb ** 0.5\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)  # Calculate R² Score\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"LightGBM MSE: {mse_lgb:.4f}\")   # Mean Squared Error\n",
    "print(f\"LightGBM RMSE: {rmse_lgb:.4f}\")  # Root Mean Squared Error\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")  # R-squared score\n",
    "\n",
    "# Step 6: Plot feature importance for LightGBM\n",
    "lgb_feature_importance = lgb_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to map feature names with importance scores\n",
    "lgb_feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': lgb_feature_importance\n",
    "})\n",
    "\n",
    "# Sort the importance values in ascending order\n",
    "lgb_feature_importance_df = lgb_feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Plot LightGBM feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(lgb_feature_importance_df['Feature'], lgb_feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for LightGBM')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd90b5-0fbc-4816-9b6e-d34dc817947b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f9a4a-17ca-4d7c-bc5b-fefbede8f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea57b1-3046-4910-858d-5cf416ecde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a0e34-a705-4adc-8000-ca7f123863c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(Transactions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8a3dd-bd2e-4622-aa0c-5c19a19f1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in categorical columns\n",
    "print(Transactions.select_dtypes(include=['object']).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e852f43-4392-4398-8166-61259050993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values\n",
    "Transactions['Property Sub Type'].fillna('Unknown', inplace=True)\n",
    "Transactions['Room(s)'].fillna('Unknown', inplace=True)\n",
    "Transactions['Parking'].fillna('Unknown', inplace=True)\n",
    "Transactions['Nearest Metro'].fillna('Unknown', inplace=True)\n",
    "Transactions['Nearest Mall'].fillna('Unknown', inplace=True)\n",
    "Transactions['Nearest Landmark'].fillna('Unknown', inplace=True)\n",
    "Transactions['Project'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Drop rows where the target variable 'Amount' is missing (if any)\n",
    "Transactions.dropna(subset=['Amount'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30be9f-bc4d-46c1-9d6a-450afb58fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Property Size (sq.m)' and 'Annual Amount' to numeric\n",
    "Transactions['Property Size (sq.m)'] = pd.to_numeric(Transactions['Property Size (sq.m)'], errors='coerce')\n",
    "Transactions['Amount'] = pd.to_numeric(Transactions['Amount'], errors='coerce')\n",
    "Transactions['Transaction Size (sq.m)'] = pd.to_numeric(Transactions['Transaction Size (sq.m)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dd576-cf2b-49a5-afb4-e63b41c72242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot after outlier handling\n",
    "sns.boxplot(x=Transactions['Amount'])\n",
    "plt.title(\"Boxplot of Amount Before Outlier Handling\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc4448-1012-4c7a-8b45-51c3b22a4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Detect outliers using IQR (Interquartile Range)\n",
    "Q1 = Transactions['Amount'].quantile(0.25)\n",
    "Q3 = Transactions['Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = (Transactions['Amount'] < (Q1 - 1.5 * IQR)) | (Transactions['Amount'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Remove outliers\n",
    "Transactions = Transactions[~outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08db6f-a316-4777-b36f-81509cd0325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot after outlier handling\n",
    "sns.boxplot(x=Transactions['Amount'])\n",
    "plt.title(\"Boxplot of Amount After Outlier Handling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200c6d5-29bc-46bc-9776-eff9ff26b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transactions['Transaction Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5292f-cb40-4c25-a4c2-6492b51621b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for 'Unit' in Property Type\n",
    "unit_data = Transactions[Transactions['Transaction Type'] == 'Sales']\n",
    "\n",
    "# Summary statistics for 'Unit'\n",
    "print(unit_data['Transaction Type'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8a01e-ec2a-4373-8775-cb57915d8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_data['Transaction Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840338ca-d9c4-46bb-95a5-2de70f93a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in 'Amount' using IQR\n",
    "Q1 = unit_data['Amount'].quantile(0.25)\n",
    "Q3 = unit_data['Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = (unit_data['Amount'] < (Q1 - 1.5 * IQR)) | (unit_data['Amount'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "unit_data = unit_data[~outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3d6f2-001e-44aa-b304-3474954f4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot distribution of 'Amount' for 'Sales'\n",
    "sns.histplot(unit_data['Amount'], kde=True, bins=50)\n",
    "plt.title(\"Distribution of Amount for 'Sales'\")\n",
    "plt.show()\n",
    "\n",
    "# Compare with other property types\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(x='Transaction Type', y='Amount', data=Transactions)\n",
    "plt.title(\"Amount by Transaction Type 'Sales'\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cec7f4-8717-43f5-850d-d9b7bd6b298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Property Size (sq.m)' and 'Annual Amount' to numeric\n",
    "unit_data['Property Size (sq.m)'] = pd.to_numeric(unit_data['Property Size (sq.m)'], errors='coerce')\n",
    "unit_data['Amount'] = pd.to_numeric(unit_data['Amount'], errors='coerce')\n",
    "unit_data['Transaction Size (sq.m)'] = pd.to_numeric(unit_data['Transaction Size (sq.m)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad94704-937f-454b-9611-d40efc430862",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Feature engineering: Extract year, month, and weekday from 'Transaction Date'\n",
    "unit_data['Transaction Date'] = pd.to_datetime(unit_data['Transaction Date'], errors='coerce')\n",
    "unit_data['Transaction Year'] = unit_data['Transaction Date'].dt.year\n",
    "unit_data['Transaction Month'] = unit_data['Transaction Date'].dt.month\n",
    "unit_data['Transaction Day'] = unit_data['Transaction Date'].dt.day\n",
    "unit_data['Transaction Weekday'] = unit_data['Transaction Date'].dt.weekday\n",
    "\n",
    "# Create a feature 'Size Ratio' (Property Size / Transaction Size)\n",
    "unit_data['Size Ratio'] = unit_data['Property Size (sq.m)'] / unit_data['Transaction Size (sq.m)']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b21aaa-c768-4b7d-a1b8-baa9c1f5edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: Extract year, month, and weekday from 'Transaction Date'\n",
    "unit_data['Transaction Date'] = pd.to_datetime(unit_data['Transaction Date'], errors='coerce')\n",
    "unit_data['Year'] = unit_data['Transaction Date'].dt.year\n",
    "unit_data['Month'] = unit_data['Transaction Date'].dt.month\n",
    "unit_data['Day'] = unit_data['Transaction Date'].dt.day\n",
    "unit_data['Week'] = unit_data['Transaction Date'].dt.weekday\n",
    "\n",
    "# Create a feature 'Size Ratio' (Property Size / Transaction Size)\n",
    "unit_data['Size Ratio'] = unit_data['Property Size (sq.m)'] / unit_data['Transaction Size (sq.m)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc067a08-8e8b-4e85-857b-33f4e0375094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average prices the previous month/week (for the same kind of property)\n",
    "\n",
    "# Step 3: Define property characteristics for grouping\n",
    "property_characteristics = ['Area', 'Property Type', 'Property Sub Type', 'Usage', 'Is Free Hold?']\n",
    "\n",
    "# Step 4: Calculate average prices for the previous month\n",
    "unit_data['Prev_Month_Avg_Price'] = (\n",
    "    unit_data.groupby(property_characteristics + ['Year', 'Month'])['Amount']\n",
    "    .transform(lambda x: x.shift().mean())\n",
    ")\n",
    "\n",
    "# Step 5: Calculate average prices for the previous week\n",
    "unit_data['Prev_Week_Avg_Price'] = (\n",
    "    unit_data.groupby(property_characteristics + ['Year', 'Week'])['Amount']\n",
    "    .transform(lambda x: x.shift().mean())\n",
    ")\n",
    "\n",
    "# Verify the new columns\n",
    "print(unit_data[['Prev_Month_Avg_Price', 'Prev_Week_Avg_Price']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b927443-9e7e-45c4-8e7f-b5aab4a4e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b4457-5ae1-42be-850f-147cf8892bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = unit_data.drop(columns=['Amount', 'Transaction Number', 'Transaction Date'])\n",
    "y = unit_data['Amount']\n",
    "\n",
    "# Split the data into training and test sets (80-20 split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the dimensions of the splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f812c33-31c5-4329-8113-36fc6a22c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [\n",
    "    'Transaction Type', 'Transaction sub type', 'Registration type', \n",
    "    'Is Free Hold?', 'Usage', 'Area', 'Property Type', \n",
    "    'Property Sub Type', 'Room(s)', 'Parking', 'Nearest Metro', \n",
    "    'Nearest Mall', 'Nearest Landmark', 'Master Project', 'Project'\n",
    "]\n",
    "\n",
    "# Ensure the categorical columns are treated as category dtype\n",
    "for col in categorical_cols:\n",
    "    if col in X_train.columns:  # Check if column exists in the data\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_model = LGBMRegressor(objective='regression', \n",
    "                              num_iterations=1000,  # Number of boosting iterations\n",
    "                              learning_rate=0.1,  # Learning rate\n",
    "                              max_depth=6,  # Tree depth\n",
    "                              random_state=42)\n",
    "\n",
    "lgb_model.fit(X_train, y_train, categorical_feature=categorical_cols)\n",
    "\n",
    "# Predict on test data\n",
    "lgb_preds = lgb_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, lgb_preds)\n",
    "rmse_lgb = mse_lgb ** 0.5\n",
    "r2_lgb = r2_score(y_test, lgb_preds)  # Calculate R² Score\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"LightGBM MSE: {mse_lgb:.4f}\")   # Mean Squared Error\n",
    "print(f\"LightGBM RMSE: {rmse_lgb:.4f}\")  # Root Mean Squared Error\n",
    "print(f\"LightGBM R² Score: {r2_lgb:.4f}\")  # R-squared score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70c35c-91fb-45ed-92ae-857c09432ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LightGBM feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lgb_feature_importance = lgb_model.feature_importances_\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_idx = lgb_feature_importance.argsort()\n",
    "plt.barh(X_train.columns[sorted_idx], lgb_feature_importance[sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('LightGBM Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df4fcd-6cef-469c-998a-91729d47041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [\n",
    "    'Transaction Type', 'Transaction sub type', 'Registration type', \n",
    "    'Is Free Hold?', 'Usage', 'Area', 'Property Type', \n",
    "    'Property Sub Type', 'Room(s)', 'Parking', 'Nearest Metro', \n",
    "    'Nearest Mall', 'Nearest Landmark', 'Master Project', 'Project'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40694032-30de-494f-9e93-b5d41fae07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in categorical columns with a placeholder string 'missing'\n",
    "for col in categorical_cols:\n",
    "    if col in X_train.columns:\n",
    "        # Define 'missing' as a valid category for both train and test\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "        # Set 'missing' as an additional category by reassigning the column\n",
    "        X_train[col] = X_train[col].cat.add_categories('missing')\n",
    "        X_test[col] = X_test[col].cat.add_categories('missing')\n",
    "\n",
    "        # Fill NaN values with 'missing'\n",
    "        X_train[col] = X_train[col].fillna('missing')\n",
    "        X_test[col] = X_test[col].fillna('missing')\n",
    "\n",
    "# Ensure the categorical columns are treated as category dtype\n",
    "for col in categorical_cols:\n",
    "    if col in X_train.columns:  # Check if column exists in the data\n",
    "        X_train[col] = X_train[col].astype('category')\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "# Categorical features: Get the indices of the categorical columns in X_train\n",
    "cat_features = [i for i, col in enumerate(X_train.columns) if X_train[col].dtype.name == 'category']\n",
    "\n",
    "# Train CatBoost model\n",
    "cat_model = CatBoostRegressor(iterations=1000,  # Number of boosting iterations\n",
    "                              learning_rate=0.1,  # Learning rate\n",
    "                              depth=6,  # Tree depth\n",
    "                              cat_features=cat_features,  # List of categorical feature indices\n",
    "                              random_seed=42,  # Random seed for reproducibility\n",
    "                              verbose=200)  # Print progress every 200 iterations\n",
    "\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "cat_preds = cat_model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "mse = mean_squared_error(y_test, cat_preds)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, cat_preds)  # Calculate R² Score\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"MSE: {mse:.4f}\")   # Mean Squared Error\n",
    "print(f\"RMSE: {rmse:.4f}\")  # Root Mean Squared Error\n",
    "print(f\"R² Score: {r2:.4f}\")  # R-squared score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0eba6-20ed-47ba-a027-c55fc6c31f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importance and sort them from highest to lowest\n",
    "cat_feature_importance = cat_model.get_feature_importance()\n",
    "sorted_idx = np.argsort(cat_feature_importance)[::-1]  # Sort in descending order\n",
    "\n",
    "# Sort the features and importances\n",
    "sorted_features = X_train.columns[sorted_idx]\n",
    "sorted_importance = cat_feature_importance[sorted_idx]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_importance)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for CatBoost')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e2f68-2093-442b-bce7-a88939e3b55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
